Files already downloaded and verified
Step [0/390]	 Loss: 4.230543613433838
Step [50/390]	 Loss: 4.190739631652832
Step [100/390]	 Loss: 4.341214179992676
Step [150/390]	 Loss: 4.248638153076172
Step [200/390]	 Loss: 4.24514102935791
Step [250/390]	 Loss: 4.3434906005859375
Step [300/390]	 Loss: 4.245536804199219
Step [350/390]	 Loss: 4.2255964279174805
Epoch [0/100]	 Loss: 4.261823862026899	 lr: 0.1
/project/6060173/stephy/HistoKT/env/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Step [0/390]	 Loss: 4.330956935882568
Step [50/390]	 Loss: 4.247320652008057
Step [100/390]	 Loss: 4.281148433685303
Step [150/390]	 Loss: 4.276610374450684
Step [200/390]	 Loss: 4.259979724884033
Step [250/390]	 Loss: 4.230991840362549
Step [300/390]	 Loss: 4.215662002563477
Step [350/390]	 Loss: 4.21774959564209
Epoch [1/100]	 Loss: 4.262772904909574	 lr: 0.1
Step [0/390]	 Loss: 4.327425003051758
Step [50/390]	 Loss: 4.241893768310547
Step [100/390]	 Loss: 4.285977363586426
Step [150/390]	 Loss: 4.277804374694824
Step [200/390]	 Loss: 4.295447826385498
Step [250/390]	 Loss: 4.245882034301758
Step [300/390]	 Loss: 4.316993713378906
Step [350/390]	 Loss: 4.26223087310791
Epoch [2/100]	 Loss: 4.26914610740466	 lr: 0.1
Step [0/390]	 Loss: 4.251692771911621
Step [50/390]	 Loss: 4.233336448669434
Step [100/390]	 Loss: 4.310640811920166
Step [150/390]	 Loss: 4.21600341796875
Step [200/390]	 Loss: 4.1909379959106445
Step [250/390]	 Loss: 4.304225444793701
Step [300/390]	 Loss: 4.222866535186768
Step [350/390]	 Loss: 4.252471923828125
Epoch [3/100]	 Loss: 4.265967875260573	 lr: 0.1
Step [0/390]	 Loss: 4.335405349731445
Step [50/390]	 Loss: 4.226077556610107
Step [100/390]	 Loss: 4.3049163818359375
Step [150/390]	 Loss: 4.207846641540527
Step [200/390]	 Loss: 4.286885738372803
Step [250/390]	 Loss: 4.324970722198486
Step [300/390]	 Loss: 4.2546067237854
Step [350/390]	 Loss: 4.216197967529297
Epoch [4/100]	 Loss: 4.268204103372036	 lr: 0.1
Step [0/390]	 Loss: 4.244008541107178
Step [50/390]	 Loss: 4.296746253967285
Step [100/390]	 Loss: 4.191019535064697
Step [150/390]	 Loss: 4.261882781982422
Step [200/390]	 Loss: 4.299483776092529
Step [250/390]	 Loss: 4.300075054168701
Step [300/390]	 Loss: 4.350314617156982
Step [350/390]	 Loss: 4.202702522277832
Epoch [5/100]	 Loss: 4.260294657487136	 lr: 0.1
Step [0/390]	 Loss: 4.324021339416504
Step [50/390]	 Loss: 4.241996765136719
Step [100/390]	 Loss: 4.318216323852539
Step [150/390]	 Loss: 4.347088813781738
Step [200/390]	 Loss: 4.312135696411133
Step [250/390]	 Loss: 4.1958112716674805
Step [300/390]	 Loss: 4.245556354522705
Step [350/390]	 Loss: 4.250640392303467
Epoch [6/100]	 Loss: 4.259420903523763	 lr: 0.1
Step [0/390]	 Loss: 4.279791831970215
Step [50/390]	 Loss: 4.272461891174316
Step [100/390]	 Loss: 4.242919921875
Step [150/390]	 Loss: 4.259947299957275
Step [200/390]	 Loss: 4.291696548461914
Step [250/390]	 Loss: 4.2325758934021
Step [300/390]	 Loss: 4.286606311798096
Step [350/390]	 Loss: 4.270871639251709
Epoch [7/100]	 Loss: 4.260541835198036	 lr: 0.1
Step [0/390]	 Loss: 4.221244812011719
Step [50/390]	 Loss: 4.309433460235596
Step [100/390]	 Loss: 4.284979820251465
Step [150/390]	 Loss: 4.292891979217529
Step [200/390]	 Loss: 4.305500507354736
Step [250/390]	 Loss: 4.254024028778076
Step [300/390]	 Loss: 4.245814800262451
Step [350/390]	 Loss: 4.267723560333252
Epoch [8/100]	 Loss: 4.2606154001676115	 lr: 0.1
Step [0/390]	 Loss: 4.333522796630859
Step [50/390]	 Loss: 4.249443054199219
Step [100/390]	 Loss: 4.1966400146484375
Step [150/390]	 Loss: 4.2801666259765625
Step [200/390]	 Loss: 4.242323875427246
Step [250/390]	 Loss: 4.285013198852539
Step [300/390]	 Loss: 4.189864158630371
Step [350/390]	 Loss: 4.313809394836426
Epoch [9/100]	 Loss: 4.266415962806115	 lr: 0.1
Step [0/390]	 Loss: 4.3359150886535645
Step [50/390]	 Loss: 4.354186058044434
Step [100/390]	 Loss: 4.2569169998168945
Step [150/390]	 Loss: 4.278636932373047
Step [200/390]	 Loss: 4.206633567810059
Step [250/390]	 Loss: 4.309549331665039
Step [300/390]	 Loss: 4.265749931335449
Step [350/390]	 Loss: 4.180231094360352
Epoch [10/100]	 Loss: 4.26195411559863	 lr: 0.1
Step [0/390]	 Loss: 4.282052040100098
Step [50/390]	 Loss: 4.207321643829346
Step [100/390]	 Loss: 4.169680595397949
Step [150/390]	 Loss: 4.258208274841309
Step [200/390]	 Loss: 4.304525852203369
Step [250/390]	 Loss: 4.209832191467285
Step [300/390]	 Loss: 4.271577835083008
Step [350/390]	 Loss: 4.210254669189453
Epoch [11/100]	 Loss: 4.256449673726008	 lr: 0.1
Step [0/390]	 Loss: 4.248823642730713
Step [50/390]	 Loss: 4.290253639221191
Step [100/390]	 Loss: 4.307889461517334
Step [150/390]	 Loss: 4.225040912628174
Step [200/390]	 Loss: 4.32691764831543
Step [250/390]	 Loss: 4.269283771514893
Step [300/390]	 Loss: 4.2399797439575195
Step [350/390]	 Loss: 4.284971237182617
Epoch [12/100]	 Loss: 4.260533897693341	 lr: 0.1
Step [0/390]	 Loss: 4.261345386505127
Step [50/390]	 Loss: 4.28790807723999
Step [100/390]	 Loss: 4.247138023376465
Step [150/390]	 Loss: 4.2528839111328125
Step [200/390]	 Loss: 4.262416362762451
Step [250/390]	 Loss: 4.223762035369873
Step [300/390]	 Loss: 4.269862651824951
Step [350/390]	 Loss: 4.270435333251953
Epoch [13/100]	 Loss: 4.264176845550537	 lr: 0.1
Step [0/390]	 Loss: 4.206931114196777
Step [50/390]	 Loss: 4.287598133087158
Step [100/390]	 Loss: 4.3365349769592285
Step [150/390]	 Loss: 4.224387168884277
Step [200/390]	 Loss: 4.2962541580200195
Step [250/390]	 Loss: 4.320669174194336
Step [300/390]	 Loss: 4.317804336547852
Step [350/390]	 Loss: 4.277484893798828
Epoch [14/100]	 Loss: 4.259252782968375	 lr: 0.1
Step [0/390]	 Loss: 4.256417751312256
Step [50/390]	 Loss: 4.311513423919678
Step [100/390]	 Loss: 4.303401947021484
Step [150/390]	 Loss: 4.197911262512207
Step [200/390]	 Loss: 4.322763442993164
Step [250/390]	 Loss: 4.269615173339844
Step [300/390]	 Loss: 4.238210678100586
Step [350/390]	 Loss: 4.272015571594238
Epoch [15/100]	 Loss: 4.2594488351773	 lr: 0.1
Step [0/390]	 Loss: 4.252866268157959
Step [50/390]	 Loss: 4.302524566650391
Step [100/390]	 Loss: 4.241619110107422
Step [150/390]	 Loss: 4.253292560577393
Step [200/390]	 Loss: 4.167966842651367
Step [250/390]	 Loss: 4.182529449462891
Step [300/390]	 Loss: 4.288507461547852
Step [350/390]	 Loss: 4.320067405700684
Epoch [16/100]	 Loss: 4.257132631693131	 lr: 0.1
slurmstepd: error: *** JOB 5842767 ON cdr2596 CANCELLED AT 2021-06-23T07:57:33 ***

Files already downloaded and verified
/project/6060173/stephy/HistoKT/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Step [0/390]	 Loss: 5.535802841186523
Step [50/390]	 Loss: 5.520301818847656
Step [100/390]	 Loss: 5.527216911315918
Step [150/390]	 Loss: 5.510956764221191
Step [200/390]	 Loss: 5.517330169677734
Step [250/390]	 Loss: 5.525601387023926
Step [300/390]	 Loss: 5.518608093261719
Step [350/390]	 Loss: 5.534934043884277
Epoch [0/100]	 Loss: 5.525719816256792	 lr: 0.0
/project/6060173/stephy/HistoKT/env/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Step [0/390]	 Loss: 5.531582355499268
Step [50/390]	 Loss: 5.52575159072876
Step [100/390]	 Loss: 5.531441688537598
Step [150/390]	 Loss: 5.519217491149902
Step [200/390]	 Loss: 5.522426605224609
Step [250/390]	 Loss: 5.5188493728637695
Step [300/390]	 Loss: 5.535697937011719
Step [350/390]	 Loss: 5.543587684631348
Epoch [1/100]	 Loss: 5.526112942817884	 lr: 0.0
Step [0/390]	 Loss: 5.52358865737915
Step [50/390]	 Loss: 5.530167579650879
Step [100/390]	 Loss: 5.513907432556152
Step [150/390]	 Loss: 5.540783405303955
Step [200/390]	 Loss: 5.532370090484619
Step [250/390]	 Loss: 5.522468090057373
Step [300/390]	 Loss: 5.523902893066406
Step [350/390]	 Loss: 5.513831615447998
Epoch [2/100]	 Loss: 5.525586360540146	 lr: 0.0
Step [0/390]	 Loss: 5.516487121582031
Step [50/390]	 Loss: 5.534943103790283
Step [100/390]	 Loss: 5.527239799499512
Step [150/390]	 Loss: 5.539914608001709
Step [200/390]	 Loss: 5.530973434448242
Step [250/390]	 Loss: 5.527637004852295
Step [300/390]	 Loss: 5.518550872802734
Step [350/390]	 Loss: 5.521104335784912
Epoch [3/100]	 Loss: 5.525611186638857	 lr: 0.0
Step [0/390]	 Loss: 5.516324520111084
Step [50/390]	 Loss: 5.526432037353516
Step [100/390]	 Loss: 5.528618812561035
Step [150/390]	 Loss: 5.531051158905029
Step [200/390]	 Loss: 5.516570568084717
Step [250/390]	 Loss: 5.533913612365723
Step [300/390]	 Loss: 5.527560710906982
Step [350/390]	 Loss: 5.534071922302246
Epoch [4/100]	 Loss: 5.525581412437635	 lr: 0.0
Step [0/390]	 Loss: 5.526745319366455
Step [50/390]	 Loss: 5.528753757476807
Step [100/390]	 Loss: 5.520829677581787
Step [150/390]	 Loss: 5.52470064163208
Step [200/390]	 Loss: 5.539008140563965
Step [250/390]	 Loss: 5.526472091674805
Step [300/390]	 Loss: 5.531693458557129
Step [350/390]	 Loss: 5.533445358276367
Epoch [5/100]	 Loss: 5.5252633657210914	 lr: 0.0
Step [0/390]	 Loss: 5.5230512619018555
Step [50/390]	 Loss: 5.50485897064209
Step [100/390]	 Loss: 5.534350395202637
Step [150/390]	 Loss: 5.535361289978027
Step [200/390]	 Loss: 5.532176494598389
Step [250/390]	 Loss: 5.528299331665039
Step [300/390]	 Loss: 5.519495964050293
Step [350/390]	 Loss: 5.539681434631348
Epoch [6/100]	 Loss: 5.5252746092967495	 lr: 0.0
Step [0/390]	 Loss: 5.5219645500183105
Step [50/390]	 Loss: 5.528885364532471
Step [100/390]	 Loss: 5.525352478027344
Step [150/390]	 Loss: 5.530774116516113
Step [200/390]	 Loss: 5.514225959777832
Step [250/390]	 Loss: 5.547408103942871
Step [300/390]	 Loss: 5.51069974899292
Step [350/390]	 Loss: 5.534965515136719
Epoch [7/100]	 Loss: 5.52564387810536	 lr: 0.0
Step [0/390]	 Loss: 5.526207447052002
Step [50/390]	 Loss: 5.521404266357422
Step [100/390]	 Loss: 5.516402244567871
Step [150/390]	 Loss: 5.530181407928467
Step [200/390]	 Loss: 5.524505615234375
Step [250/390]	 Loss: 5.520188808441162
Step [300/390]	 Loss: 5.5107221603393555
Step [350/390]	 Loss: 5.51426887512207
Epoch [8/100]	 Loss: 5.5248491935240915	 lr: 0.0
Step [0/390]	 Loss: 5.530629634857178
Step [50/390]	 Loss: 5.515658378601074
Step [100/390]	 Loss: 5.527566432952881
Step [150/390]	 Loss: 5.536472797393799
Step [200/390]	 Loss: 5.537528038024902
Step [250/390]	 Loss: 5.526073932647705
Step [300/390]	 Loss: 5.523678302764893
Step [350/390]	 Loss: 5.52608060836792
Epoch [9/100]	 Loss: 5.525496942569048	 lr: 0.0
Step [0/390]	 Loss: 5.531749248504639
Step [50/390]	 Loss: 5.539125919342041
Step [100/390]	 Loss: 5.52121114730835
Step [150/390]	 Loss: 5.524130821228027
Step [200/390]	 Loss: 5.514641761779785
Step [250/390]	 Loss: 5.532763957977295
Step [300/390]	 Loss: 5.5286946296691895
Step [350/390]	 Loss: 5.5326924324035645
Epoch [10/100]	 Loss: 5.525236402413784	 lr: 0.0
Step [0/390]	 Loss: 5.531857967376709
Step [50/390]	 Loss: 5.5260114669799805
Step [100/390]	 Loss: 5.521283149719238
Step [150/390]	 Loss: 5.543655872344971
Step [200/390]	 Loss: 5.5314741134643555
Step [250/390]	 Loss: 5.515303134918213
Step [300/390]	 Loss: 5.5324201583862305
Step [350/390]	 Loss: 5.527602195739746
Epoch [11/100]	 Loss: 5.525879731545081	 lr: 0.0
Step [0/390]	 Loss: 5.518873691558838
Step [50/390]	 Loss: 5.51963472366333
Step [100/390]	 Loss: 5.5335893630981445
Step [150/390]	 Loss: 5.533505439758301
Step [200/390]	 Loss: 5.529356479644775
Step [250/390]	 Loss: 5.536023139953613
Step [300/390]	 Loss: 5.5332350730896
Step [350/390]	 Loss: 5.527759552001953
Epoch [12/100]	 Loss: 5.525071680851472	 lr: 0.0
Step [0/390]	 Loss: 5.521281719207764
Step [50/390]	 Loss: 5.51108455657959
Step [100/390]	 Loss: 5.532080173492432
Step [150/390]	 Loss: 5.520921230316162
Step [200/390]	 Loss: 5.542020320892334
Step [250/390]	 Loss: 5.523025989532471
Step [300/390]	 Loss: 5.531554698944092
Step [350/390]	 Loss: 5.523346424102783
Epoch [13/100]	 Loss: 5.525437122736221	 lr: 0.0
Step [0/390]	 Loss: 5.53305721282959
Step [50/390]	 Loss: 5.528421401977539
Step [100/390]	 Loss: 5.533748149871826
Step [150/390]	 Loss: 5.5317912101745605
Step [200/390]	 Loss: 5.529469966888428
Step [250/390]	 Loss: 5.528528213500977
Step [300/390]	 Loss: 5.532748699188232
Step [350/390]	 Loss: 5.521258354187012
Epoch [14/100]	 Loss: 5.525098987726065	 lr: 0.0
Step [0/390]	 Loss: 5.517792701721191
Step [50/390]	 Loss: 5.52580451965332
Step [100/390]	 Loss: 5.530456066131592
Step [150/390]	 Loss: 5.5299763679504395
Step [200/390]	 Loss: 5.513878345489502
Step [250/390]	 Loss: 5.536498546600342
Step [300/390]	 Loss: 5.539269924163818
Step [350/390]	 Loss: 5.523179054260254
Epoch [15/100]	 Loss: 5.525478282341591	 lr: 0.0
slurmstepd: error: *** JOB 5803260 ON cdr2616 CANCELLED AT 2021-06-22T21:08:08 ***
